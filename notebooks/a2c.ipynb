{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "sys.path.append(ROOT_DIR)\n",
    "os.environ[\"LD_LIBRARY_PATH\"] =\"/home/daniel/anaconda3/envs/dev/lib/python3.11/site-packages/cv2/../../lib64:/home/daniel/.mujoco/mujoco210/bin:/usr/lib/nvidia\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import  IterableDataset,DataLoader\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torch.distributions.normal import Normal\n",
    "from utility import create_test_env, create_train_env, test_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7faffe39ad10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "Display(visible=False, size=(1500, 1000)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALG_ID = 'a2c_continuous'\n",
    "ENV_ID='Pendulum-v1'\n",
    "# ENV_ID='MountainCarContinuous-v0'\n",
    "VIDEO_DIR =os.path.join(ROOT_DIR,'videos',ALG_ID,ENV_ID)\n",
    "LOG_DIR = os.path.join(ROOT_DIR,'tboard',ALG_ID,ENV_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ENVS=64\n",
    "ENTROPY_COEFF = 0.01\n",
    "DISCOUNT_FACTOR = 0.99\n",
    "MAX_STEP = 200\n",
    "MAX_EPOCHS = 2001\n",
    "BATCH_SIZE = 16\n",
    "VALUE_LR = 0.001\n",
    "POLICY_LR = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy(nn.Module):\n",
    "    def __init__(self, num_features, num_outputs,hidden_size=128) -> None:\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_features=num_features, out_features=hidden_size)\n",
    "        self.hidden = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "        self.mu = nn.Linear(in_features=hidden_size, out_features=num_outputs)\n",
    "        self.sigma = nn.Linear(in_features=hidden_size, out_features=num_outputs)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = (x if torch.is_tensor(x) else torch.FloatTensor(x)).cuda()\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.hidden(x))\n",
    "\n",
    "        mu = F.tanh(self.mu(x))*2\n",
    "        sigma = F.softplus(self.sigma(x)) + 0.001\n",
    "        return mu, sigma\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def pi(self,state):\n",
    "        p = state if torch.is_tensor(state) else torch.FloatTensor(state)\n",
    "        mu,sigma = self.forward(p)\n",
    "        actions = torch.normal(mu, sigma)\n",
    "        actions = actions.cpu().numpy()\n",
    "        return actions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value(nn.Module):\n",
    "    def __init__(self, num_features,hidden_size=128) -> None:\n",
    "        super().__init__()\n",
    "        self.input = nn.Linear(in_features=num_features, out_features=hidden_size)\n",
    "        self.hidden = nn.Linear(in_features=hidden_size, out_features=hidden_size)\n",
    "        self.out = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = (x if torch.is_tensor(x) else torch.FloatTensor(x)).cuda()\n",
    "        x = F.relu(self.input(x))\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(IterableDataset):\n",
    "    def __init__(self,env,max_step,policy,discount_factor):\n",
    "        super().__init__()\n",
    "        self.env = env\n",
    "        self.max_step = max_step\n",
    "        self.policy = policy\n",
    "        self.discount_factor = discount_factor\n",
    "        \n",
    "    def __iter__(self):\n",
    "        state,_ = self.env.reset()\n",
    "        for step in range(self.max_step):\n",
    "            action = self.policy(state)\n",
    "            # obs, rews, terminateds, truncateds, infos\n",
    "            next_state,reward,done, truncated ,infos = self.env.step(action)\n",
    "            yield state.astype(np.float32) , action.astype(np.float32) , reward.astype(np.float32) , done.astype(np.int32) , next_state.astype(np.float32) \n",
    "            state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "\n",
    "class A2C(L.LightningModule):\n",
    "    def __init__(self,env_id, num_envs,value_lr = VALUE_LR,policy_lr=POLICY_LR, entropy_coeff=0.01, hidden_size=64, discount_factor=DISCOUNT_FACTOR, max_step=100, batch_size=64):\n",
    "        super().__init__()\n",
    "        self.env_id = env_id\n",
    "        self.train_env = create_train_env(env_name=env_id,num_envs=num_envs)\n",
    "        self.test_env = create_test_env(env_name=self.env_id, obs_rms=self.train_env.obs_rms, video_dir=VIDEO_DIR,episode_trigger=lambda e: e%100==0)\n",
    "        num_features = self.train_env.unwrapped.single_observation_space.shape[-1]\n",
    "        self.action_dims = self.train_env.unwrapped.single_action_space.shape[-1]\n",
    "        self.policy_model=Policy(num_features, self.action_dims,hidden_size=hidden_size)\n",
    "        self.value_model = Value(num_features, hidden_size)\n",
    "        self.num_features = num_features\n",
    "        self.target_value_model = copy.deepcopy(self.value_model)\n",
    "        self.value_lr = value_lr\n",
    "        self.policy_lr = policy_lr\n",
    "        self.automatic_optimization = False\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        state, action, reward, done, next_state = batch\n",
    "        state = state.reshape(-1,self.num_features).to(self.device)\n",
    "        action = action.reshape(-1,self.action_dims).to(self.device)\n",
    "        reward = reward.reshape(-1,1).to(self.device)\n",
    "        done = done.reshape(-1,1).to(self.device)\n",
    "        next_state=next_state.reshape(-1,self.num_features)\n",
    "        v_opt, p_opt = self.optimizers()\n",
    "        \n",
    "        state_value = self.value_model(state)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            next_state_value = self.target_value_model(next_state)\n",
    "            next_state_value[done] = 0.0\n",
    "            target = reward + self.hparams.discount_factor * next_state_value\n",
    "\n",
    "        v_loss = F.smooth_l1_loss(state_value,target)\n",
    "        self.log(\"episode/Value Loss\", v_loss)\n",
    "\n",
    "        \n",
    "\n",
    "        advantages = (target-state_value).detach()\n",
    "\n",
    "        mu, sigma = self.policy_model(state) \n",
    "        dist = Normal(mu, sigma)\n",
    "        log_prob = dist.log_prob(action).sum(dim=1, keepdim=True)\n",
    "\n",
    "        policy_loss = - log_prob * advantages\n",
    "        # entropy = dist.entropy().sum(dim=-1, keepdim=True)\n",
    "        # p_loss = (policy_loss - self.hparams.entropy_coeff*entropy).mean()\n",
    "        \n",
    "        p_loss = policy_loss.mean()\n",
    "        self.log(\"episode/Policy Loss\", policy_loss.mean())\n",
    "        # self.log(\"episode/Entropy\", entropy.mean())\n",
    "\n",
    "        v_opt.zero_grad()\n",
    "        self.manual_backward(v_loss)\n",
    "        v_opt.step()\n",
    "\n",
    "        p_opt.zero_grad()\n",
    "        self.manual_backward(p_loss)\n",
    "        p_opt.step()\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        self.test_env.obs_rms = self.train_env.obs_rms\n",
    "        average_return = test_agent(self.test_env, self.policy_model.pi, episodes=1, max_steps=MAX_STEP,video_dir=VIDEO_DIR)\n",
    "        self.log(\"episode/Average Return\", average_return)\n",
    "\n",
    "        if self.current_epoch > 0 and self.current_epoch % 10 == 0:\n",
    "            self.target_value_model.load_state_dict(self.value_model.state_dict())\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_ds = MyDataset(env=self.train_env, discount_factor=self.hparams.discount_factor, max_step=self.hparams.max_step,policy=self.policy_model.pi,)\n",
    "        train_dl = DataLoader(train_ds, batch_size=self.hparams.batch_size)\n",
    "        return train_dl\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        policy_optimizer = AdamW(self.policy_model.parameters(), lr=self.policy_lr)\n",
    "        value_optimizer = AdamW(self.value_model.parameters(), lr=self.value_lr)\n",
    "        return value_optimizer,policy_optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/dev/lib/python3.11/site-packages/gymnasium/vector/__init__.py:53: UserWarning: \u001b[33mWARN: `gymnasium.vector.make(...)` is deprecated and will be replaced by `gymnasium.make_vec(...)` in v1.0\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/home/daniel/anaconda3/envs/dev/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.single_observation_space to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.single_observation_space` for environment variables or `env.get_wrapper_attr('single_observation_space')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/daniel/anaconda3/envs/dev/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.obs_rms to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.obs_rms` for environment variables or `env.get_wrapper_attr('obs_rms')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/daniel/anaconda3/envs/dev/lib/python3.11/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "a2c = A2C(env_id=ENV_ID, \n",
    "                  policy_lr=POLICY_LR, \n",
    "                  value_lr=VALUE_LR,\n",
    "                  num_envs=NUM_ENVS, \n",
    "                  discount_factor=DISCOUNT_FACTOR,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  max_step=MAX_STEP,\n",
    "                  entropy_coeff=ENTROPY_COEFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A2C(\n",
       "  (policy_model): Policy(\n",
       "    (input): Linear(in_features=3, out_features=64, bias=True)\n",
       "    (hidden): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (mu): Linear(in_features=64, out_features=1, bias=True)\n",
       "    (sigma): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (value_model): Value(\n",
       "    (input): Linear(in_features=3, out_features=64, bias=True)\n",
       "    (hidden): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (target_value_model): Value(\n",
       "    (input): Linear(in_features=3, out_features=64, bias=True)\n",
       "    (hidden): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator='gpu',\n",
    "    devices=1,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    logger=TensorBoardLogger(save_dir=os.path.dirname(LOG_DIR), name=ENV_ID)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r $VIDEO_DIR\n",
    "!rm -r $LOG_DIR\n",
    "!mkdir -p $LOG_DIR\n",
    "!mkdir -p $VIDEO_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 771948), started 9:05:27 ago. (Use '!kill 771948' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a97c2868e77cc90\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a97c2868e77cc90\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $LOG_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name               | Type   | Params\n",
      "----------------------------------------------\n",
      "0 | policy_model       | Policy | 4.5 K \n",
      "1 | value_model        | Value  | 4.5 K \n",
      "2 | target_value_model | Value  | 4.5 K \n",
      "----------------------------------------------\n",
      "13.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "13.5 K    Total params\n",
      "0.054     Total estimated model params size (MB)\n",
      "/home/daniel/anaconda3/envs/dev/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13006bb41984e7b846ef2846d147277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/dev/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.obs_rms to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.obs_rms` for environment variables or `env.get_wrapper_attr('obs_rms')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/dev/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.obs_rms to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.obs_rms` for environment variables or `env.get_wrapper_attr('obs_rms')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-100.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-100.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-100.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-200.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-200.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-200.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-300.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-300.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-300.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-400.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-400.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-400.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-500.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-500.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-500.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-600.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-600.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-600.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-700.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-700.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-700.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-800.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-800.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-800.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-900.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-900.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-900.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1000.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1000.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1000.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1100.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1100.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1100.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1200.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1200.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1200.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1300.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1300.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1300.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1400.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1400.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1400.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1500.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1500.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1500.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1600.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1600.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1600.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1700.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1700.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1700.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1800.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1800.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1800.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1900.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1900.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-1900.mp4\n",
      "Moviepy - Building video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-2000.mp4.\n",
      "Moviepy - Writing video /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-2000.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2001` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/daniel/src/rl4fun/videos/a2c_continuous/Pendulum-v1/rl-video-episode-2000.mp4\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=a2c,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
